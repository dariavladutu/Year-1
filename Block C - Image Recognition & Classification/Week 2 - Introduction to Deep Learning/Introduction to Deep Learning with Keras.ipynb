{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Deep Learning with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Sequential model and Dense layer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add an input layer and a hidden layer with 10 neurons\n",
    "model.add(Dense(10, input_shape=(2,), activation=\"relu\"))\n",
    "\n",
    "# Add a 1-neuron output layer\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Summarise your model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Model: \"sequential\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "dense (Dense)                (None, 10)                30        \n",
    "_________________________________________________________________\n",
    "dense_1 (Dense)              (None, 1)                 11        \n",
    "=================================================================\n",
    "Total params: 41\n",
    "Trainable params: 41\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________ '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add a Dense layer with 50 neurons and an input of 1 neuron\n",
    "model.add(Dense(50, input_shape=(1,), activation='relu'))\n",
    "\n",
    "# Add two Dense layers with 50 neurons and relu activation\n",
    "model.add(Dense(50,activation='relu'))\n",
    "model.add(Dense(50,activation='relu'))\n",
    "\n",
    "# End your model with a Dense layer and no activation\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile your model\n",
    "model.compile(optimizer = 'adam', loss = 'mse')\n",
    "\n",
    "print(\"Training started..., this can take a while:\")\n",
    "\n",
    "# Fit your model on your data for 30 epochs\n",
    "model.fit(time_steps,y_positions, epochs = 30)\n",
    "\n",
    "# Evaluate your model \n",
    "print(\"Final loss value:\",model.evaluate(time_steps,y_positions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Training started..., this can take a while:\n",
    "Epoch 1/30\n",
    "\n",
    " 1/63 [..............................] - ETA: 19s - loss: 2205.6104\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "59/63 [===========================>..] - ETA: 0s - loss: 1615.3015 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "63/63 [==============================] - 0s 888us/step - loss: 1572.2054\n",
    "Epoch 2/30\n",
    "\n",
    " 1/63 [..............................] - ETA: 0s - loss: 824.0054\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "63/63 [==============================] - 0s 807us/step - loss: 246.3038\n",
    "Epoch 3/30\n",
    "\n",
    " 1/63 [..............................] - ETA: 0s - loss: 117.8673\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "63/63 [==============================] - 0s 767us/step - loss: 136.0419\n",
    "Epoch 4/30\n",
    "\n",
    " 1/63 [..............................] - ETA: 0s - loss: 133.4181\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "63/63 [==============================] - ETA: 0s - loss: 120.4804\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "63/63 [==============================] - 0s 817us/step - loss: 120.4804\n",
    "Epoch 5/30\n",
    "\n",
    " 1/63 [..............................] - ETA: 0s - loss: 86.0217\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "60/63 [===========================>..] - ETA: 0s - loss: 106.4329\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "63/63 [==============================] - 0s 910us/step - loss: 104.8979\n",
    "Epoch 6/30\n",
    "\n",
    " 1/63 [..............................] - ETA: 0s - loss: 80.4282\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "51/63 [=======================>......] - ETA: 0s - loss: 88.5218\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "63/63 [==============================] - 0s 1ms/step - loss: 86.8851\n",
    "Epoch 7/30\n",
    "\n",
    " 1/63 [..............................] - ETA: 0s - loss: 85.3245\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "51/63 [=======================>......] - ETA: 0s - loss: 70.6711\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "63/63 [==============================] - 0s 989us/step - loss: 70.7049\n",
    "Epoch 8/30\n",
    "\n",
    " 1/63 [..............................] - ETA: 0s - loss: 63.6505\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "48/63 [=====================>........] - ETA: 0s - loss: 55.7476\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "63/63 [==============================] - 0s 1ms/step - loss: 53.1416\n",
    "Epoch 9/30\n",
    "\n",
    " 1/63 [..............................] - ETA: 0s - loss: 23.2847\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "55/63 [=========================>....] - ETA: 0s - loss: 38.5440\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "63/63 [==============================] - 0s 934us/step - loss: 37.7381\n",
    "Epoch 10/30\n",
    "\n",
    " 1/63 [..............................] - ETA: 0s - loss: 34.9173\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "51/63 [=======================>......] - ETA: 0s - loss: 26.6147\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "63/63 [==============================] - 0s 1ms/step - loss: 25.4356\n",
    "Epoch 11/30\n",
    "\n",
    " 1/63 [..............................] - ETA: 0s - loss: 28.6145\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "43/63 [===================>..........] - ETA: 0s - loss: 17.9631\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "63/63 [==============================] - 0s 1ms/step - loss: 16.4396\n",
    "Epoch 12/30\n",
    "\n",
    " 1/63 [..............................] - ETA: 0s - loss: 17.0322\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "48/63 [=====================>........] - ETA: 0s - loss: 11.8481\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "63/63 [==============================] - 0s 1ms/step - loss: 11.3304\n",
    "Epoch 13/30\n",
    "\n",
    " 1/63 [..............................] - ETA: 0s - loss: 11.9423\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "53/63 [========================>.....] - ETA: 0s - loss: 7.8649 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "63/63 [==============================] - 0s 982us/step - loss: 7.6623\n",
    "Epoch 14/30\n",
    "\n",
    " 1/63 [..............................] - ETA: 0s - loss: 4.8782\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "44/63 [===================>..........] - ETA: 0s - loss: 5.2236\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "63/63 [==============================] - 0s 1ms/step - loss: 4.9422\n",
    "Epoch 15/30\n",
    "\n",
    " 1/63 [..............................] - ETA: 0s - loss: 3.9131\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "57/63 [==========================>...] - ETA: 0s - loss: 3.5125\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "63/63 [==============================] - 0s 900us/step - loss: 3.4431\n",
    "Epoch 16/30\n",
    "\n",
    " 1/63 [..............................] - ETA: 0s - loss: 2.0455\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "35/63 [===============>..............] - ETA: 0s - loss: 2.5331\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "63/63 [==============================] - ETA: 0s - loss: 2.5180\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "63/63 [==============================] - 0s 2ms/step - loss: 2.5180\n",
    "Epoch 17/30\n",
    "\n",
    " 1/63 [..............................] - ETA: 0s - loss: 1.1902\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "47/63 [=====================>........] - ETA: 0s - loss: 2.1280\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "63/63 [==============================] - 0s 1ms/step - loss: 1.9478\n",
    "Epoch 18/30\n",
    "\n",
    " 1/63 [..............................] - ETA: 0s - loss: 1.0205\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "51/63 [=======================>......] - ETA: 0s - loss: 1.5229\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "63/63 [==============================] - 0s 994us/step - loss: 1.4100\n",
    "Epoch 19/30\n",
    "\n",
    " 1/63 [..............................] - ETA: 0s - loss: 0.9614\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "60/63 [===========================>..] - ETA: 0s - loss: 1.0942\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "63/63 [==============================] - 0s 862us/step - loss: 1.0857\n",
    "Epoch 20/30\n",
    "\n",
    " 1/63 [..............................] - ETA: 0s - loss: 1.7328\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "59/63 [===========================>..] - ETA: 0s - loss: 1.1468\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "63/63 [==============================] - 0s 891us/step - loss: 1.1311\n",
    "Epoch 21/30\n",
    "\n",
    " 1/63 [..............................] - ETA: 0s - loss: 0.8590\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "48/63 [=====================>........] - ETA: 0s - loss: 0.8477\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "63/63 [==============================] - 0s 1ms/step - loss: 0.7961\n",
    "Epoch 22/30\n",
    "\n",
    " 1/63 [..............................] - ETA: 0s - loss: 0.3995\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "53/63 [========================>.....] - ETA: 0s - loss: 0.6245\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "63/63 [==============================] - 0s 986us/step - loss: 0.6154\n",
    "Epoch 23/30\n",
    "\n",
    " 1/63 [..............................] - ETA: 0s - loss: 0.6031\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "54/63 [========================>.....] - ETA: 0s - loss: 0.5128\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "63/63 [==============================] - 0s 966us/step - loss: 0.4983\n",
    "Epoch 24/30\n",
    "\n",
    " 1/63 [..............................] - ETA: 0s - loss: 0.3652\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "51/63 [=======================>......] - ETA: 0s - loss: 0.4393\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "63/63 [==============================] - 0s 1ms/step - loss: 0.4164\n",
    "Epoch 25/30\n",
    "\n",
    " 1/63 [..............................] - ETA: 0s - loss: 0.1485\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "56/63 [=========================>....] - ETA: 0s - loss: 0.3790\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "63/63 [==============================] - 0s 909us/step - loss: 0.3655\n",
    "Epoch 26/30\n",
    "\n",
    " 1/63 [..............................] - ETA: 0s - loss: 0.2637\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "60/63 [===========================>..] - ETA: 0s - loss: 0.3105\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "63/63 [==============================] - 0s 854us/step - loss: 0.3091\n",
    "Epoch 27/30\n",
    "\n",
    " 1/63 [..............................] - ETA: 0s - loss: 0.1403\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "59/63 [===========================>..] - ETA: 0s - loss: 0.2793\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "63/63 [==============================] - 0s 874us/step - loss: 0.2876\n",
    "Epoch 28/30\n",
    "\n",
    " 1/63 [..............................] - ETA: 0s - loss: 0.0984\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "59/63 [===========================>..] - ETA: 0s - loss: 0.2446\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "63/63 [==============================] - 0s 868us/step - loss: 0.2453\n",
    "Epoch 29/30\n",
    "\n",
    " 1/63 [..............................] - ETA: 0s - loss: 0.4527\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "58/63 [==========================>...] - ETA: 0s - loss: 0.2003\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "63/63 [==============================] - 0s 891us/step - loss: 0.2018\n",
    "Epoch 30/30\n",
    "\n",
    " 1/63 [..............................] - ETA: 0s - loss: 0.0929\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "56/63 [=========================>....] - ETA: 0s - loss: 0.1818\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "63/63 [==============================] - 0s 1ms/step - loss: 0.1817\n",
    "\n",
    " 1/63 [..............................] - ETA: 6s - loss: 1.9265\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "63/63 [==============================] - 0s 773us/step - loss: 0.2141\n",
    "Final loss value: 0.21409407258033752'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the twenty minutes orbit\n",
    "twenty_min_orbit = model.predict(np.arange(-10, 11))\n",
    "\n",
    "# Plot the twenty minute orbit \n",
    "plot_orbit(twenty_min_orbit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the sequential model and dense layer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Create a sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add a dense layer \n",
    "model.add(Dense(1, input_shape=(4,), activation='sigmoid'))\n",
    "\n",
    "# Compile your model\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# Display a summary of your model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Model: \"sequential\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "dense (Dense)                (None, 1)                 5         \n",
    "=================================================================\n",
    "Total params: 5\n",
    "Trainable params: 5\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train your model for 20 epochs\n",
    "model.fit(X_train, y_train, epochs = 20)\n",
    "\n",
    "# Evaluate your model accuracy on the test set\n",
    "accuracy = model.evaluate(X_test, y_test)[1]\n",
    "\n",
    "# Print accuracy\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Accuracy: 0.844660222530365'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-class model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a sequential model\n",
    "model = Sequential()\n",
    "  \n",
    "# Add 3 dense layers of 128, 64 and 32 neurons each\n",
    "model.add(Dense(128, input_shape=(2,), activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "  \n",
    "# Add a dense layer with as many neurons as competitors\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "  \n",
    "# Compile your model using categorical_crossentropy loss\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Transform into a categorical variable\n",
    "darts.competitor = pd.Categorical(darts.competitor)\n",
    "\n",
    "# Assign a number to each category (label encoding)\n",
    "darts.competitor = darts.competitor.cat.codes \n",
    "\n",
    "# Print the label encoded competitors\n",
    "print('Label encoded competitors: \\n',darts.competitor.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Label encoded competitors: \n",
    " 0    2\n",
    "1    3\n",
    "2    1\n",
    "3    0\n",
    "4    2\n",
    "Name: competitor, dtype: int8'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-label classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add a hidden layer of 64 neurons and a 20 neuron's input\n",
    "model.add(Dense(64, input_shape=(20,), activation='relu'))\n",
    "\n",
    "# Add an output layer of 3 neurons with sigmoid activation\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "\n",
    "# Compile your model with binary crossentropy loss\n",
    "model.compile(optimizer='adam',\n",
    "           loss = 'binary_crossentropy',\n",
    "           metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Model: \"sequential\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "dense (Dense)                (None, 64)                1344      \n",
    "_________________________________________________________________\n",
    "dense_1 (Dense)              (None, 3)                 195       \n",
    "=================================================================\n",
    "Total params: 1,539\n",
    "Trainable params: 1,539\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train for 100 epochs using a validation split of 0.2\n",
    "model.fit(sensors_train, parcels_train, epochs = 100, validation_split = 0.2)\n",
    "\n",
    "# Predict on sensors_test and round up the predictions\n",
    "preds = model.predict(sensors_test)\n",
    "preds_rounded = np.round(preds)\n",
    "\n",
    "# Print rounded preds\n",
    "print('Rounded Predictions: \\n', preds_rounded)\n",
    "\n",
    "# Evaluate your model's accuracy on the test data\n",
    "accuracy = model.evaluate(sensors_test, parcels_test)[1]\n",
    "\n",
    "# Print accuracy\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Accuracy: 0.6399999856948853'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## History callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train your model and save its history\n",
    "h_callback = model.fit(X_train, y_train, epochs = 25,\n",
    "               validation_data=(X_test, y_test))\n",
    "\n",
    "# Plot train vs test loss during training\n",
    "plot_loss(h_callback.history['loss'], h_callback.history['val_loss'])\n",
    "\n",
    "# Plot train vs test accuracy during training\n",
    "plot_accuracy(h_callback.history['accuracy'], h_callback.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the early stopping callback\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define a callback to monitor val_accuracy\n",
    "monitor_val_acc = EarlyStopping(monitor='val_accuracy', \n",
    "                       patience=5)\n",
    "\n",
    "# Train your model using the early stopping callback\n",
    "model.fit(X_train, y_train, \n",
    "           epochs=1000, validation_data=(X_test, y_test),\n",
    "           callbacks= [monitor_val_acc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early Stopping and Model Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the EarlyStopping and ModelCheckpoint callbacks\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Early stop on validation accuracy\n",
    "monitor_val_acc = EarlyStopping(monitor = 'val_accuracy', patience = 3)\n",
    "\n",
    "# Save the best model as best_banknote_model.hdf5\n",
    "model_checkpoint = ModelCheckpoint('best_banknote_model.hdf5', save_best_only = True)\n",
    "\n",
    "# Fit your model for a stupid amount of epochs\n",
    "h_callback = model.fit(X_train, y_train,\n",
    "                    epochs = 1000000000000,\n",
    "                    callbacks = [model_checkpoint, monitor_val_acc],\n",
    "                    validation_data = (X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
