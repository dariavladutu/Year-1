{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drivewheel</th>\n",
       "      <th>fueltype</th>\n",
       "      <th>aspiration</th>\n",
       "      <th>doornumber</th>\n",
       "      <th>carbody</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>fwd</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>fwd</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>wagon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>4wd</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>wagon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>fwd</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>wagon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>fwd</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>hatchback</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>fwd</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>wagon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>fwd</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>fwd</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>fwd</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>hatchback</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>rwd</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>hatchback</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    drivewheel fueltype aspiration doornumber    carbody\n",
       "62         fwd      gas        std       four      sedan\n",
       "130        fwd      gas        std       four      wagon\n",
       "154        4wd      gas        std       four      wagon\n",
       "36         fwd      gas        std       four      wagon\n",
       "175        fwd      gas        std       four  hatchback\n",
       "102        fwd      gas        std       four      wagon\n",
       "191        fwd      gas        std       four      sedan\n",
       "103        fwd      gas        std       four      sedan\n",
       "38         fwd      gas        std        two  hatchback\n",
       "57         rwd      gas        std        two  hatchback"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# rename your dataset to car-price.csv\n",
    "df = pd.read_csv('car-price.csv', delimiter=';')\n",
    "\n",
    "# we will take two variables,\n",
    "# we will use doornumber as our target\n",
    "# and the others as our indpendent variables\n",
    "df = df[['drivewheel','fueltype','aspiration','doornumber','carbody']]\n",
    "\n",
    "df.sample(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Gini Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable drivewheel has Gini Index of 0.4865\n",
      "\n",
      "Variable fueltype has Gini Index of 0.4745\n",
      "\n",
      "Variable aspiration has Gini Index of 0.4921\n",
      "\n",
      "Variable carbody has Gini Index of 0.2137\n",
      "\n",
      "Split on carbody With Gini Index of 0.214\n"
     ]
    }
   ],
   "source": [
    "# function will calculate gini_index for each column\n",
    "# function from scratch\n",
    "# in a dataframe\n",
    "# and print out the best column to split on\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def gini_index(dataset, targetcol):\n",
    "    \n",
    "    # store all of our columns and gini scores\n",
    "    gini_scores = []\n",
    "    \n",
    "    # iterate through each column in your dataframe\n",
    "    for col in dataset.columns:\n",
    "        \n",
    "        # skip our target column\n",
    "        # no information gain on target columns!\n",
    "        # we can't split here\n",
    "        if col == targetcol:\n",
    "            continue\n",
    "        \n",
    "        # resets for each column in your dataset\n",
    "        gini = 0\n",
    "        \n",
    "        # get the value counts for that column\n",
    "        unique_values = dataset[col].value_counts()\n",
    "        \n",
    "        # iterate through each unique value for that column\n",
    "        for key, val in unique_values.items():\n",
    "        \n",
    "            # get the target variable seperated, based on\n",
    "            # the independent variable\n",
    "            filteredDf = dataset[targetcol][dataset[col] == key].value_counts()\n",
    "            \n",
    "            # need n for the length\n",
    "            n = len(dataset)\n",
    "            \n",
    "            # sum of the value counts for that column\n",
    "            ValueSum = filteredDf.sum()\n",
    "            \n",
    "            # need the probabilities of each class\n",
    "            p = 0\n",
    "            \n",
    "            # we now have to send it to our gini impurity formula\n",
    "            for i,j in filteredDf.items():\n",
    "                p += (filteredDf[i] / ValueSum) ** 2\n",
    "            \n",
    "            # gini total for column \n",
    "            # is all uniques from each column\n",
    "            gini += (val / n) * (1-p)\n",
    "\n",
    "        print(f'Variable {col} has Gini Index of {round(gini,4)}\\n')\n",
    "        \n",
    "        # append our column name and gini score\n",
    "        gini_scores.append((col,gini))\n",
    "    \n",
    "    # sort our gini scores lowest to highest\n",
    "    split_pair = sorted(gini_scores, key=lambda x: -x[1], reverse=True)[0]\n",
    "    \n",
    "    # print out the best score\n",
    "    print(f'''Split on {split_pair[0]} With Gini Index of {round(split_pair[1],3)}''')\n",
    "        \n",
    "        \n",
    "final = gini_index(df, 'doornumber')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable drivewheel has Entropy of 0.8186\n",
      "\n",
      "Variable fueltype has Entropy of 0.3197\n",
      "\n",
      "Variable aspiration has Entropy of 0.4721\n",
      "\n",
      "Variable doornumber has Entropy of 0.6857\n",
      "\n",
      "Split on fueltype With Information Gain of 0.68\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "def entropy(dataset, targetcol):\n",
    "    # store all of our columns and entropy scores\n",
    "    entropy_scores = []\n",
    "    \n",
    "    # iterate through each column in your dataframe\n",
    "    for col in dataset.columns:\n",
    "        \n",
    "        if col == targetcol:\n",
    "            continue\n",
    "        \n",
    "        # get the value_counts normalized, saving us having to iterate through\n",
    "        # each variable\n",
    "        value_counts = dataset[col].value_counts(normalize=True, sort=False)\n",
    "        \n",
    "        # calculate our entropy for the column\n",
    "        entropy = -(value_counts * np.log(value_counts) / np.log(math.e)).sum()\n",
    "        \n",
    "        print(f'Variable {col} has Entropy of {round(entropy,4)}\\n')\n",
    "        \n",
    "        # append our column name and entropy score\n",
    "        entropy_scores.append((col,entropy))\n",
    "    \n",
    "    # sort our entropy scores lowest to highest\n",
    "    split_pair = sorted(entropy_scores, key=lambda x: -x[1], reverse=True)[0]\n",
    "    \n",
    "    # print out the best score\n",
    "    print(f'''Split on {split_pair[0]} With Information Gain of {round(1-split_pair[1],3)}''')\n",
    "        \n",
    "final = entropy(df, 'carbody')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_What are the key differences between these two metrics that help in determining how a feature should split the data to form homogeneous nodes (or leaves)?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gini score:\n",
    "- measures the probability of incorrectly classifying a randomly chosen element in the dataset.\n",
    "- tends to be biased towards larger partitions. \n",
    "- works well when the classes are imbalanced or when there is no distinct majority class. \n",
    "- it is less sensitive to outliers.\n",
    "- nodes are split based on the lowest Gini impurity.\n",
    "\n",
    "Entropy score:\n",
    "- measures the average amount of information needed to classify a sample.\n",
    "- tends to create more balanced trees, and it can be sensitive to outliers.\n",
    "- it may be more suitable when there is a clear majority class in the dataset.\n",
    "- nodes are split based on the highest information gain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Which metric should be used in what scenarios?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As previously mentioned, gini impurity is less sensitive to outliers, therefore it would be more suitable for datasets with an imbalanced class distribution, or for more complex decision trees. \n",
    "\n",
    "Entropy might be preffered for situations where there is a relatively balanced class distribution in the dataset. It may be suitable when the goal is to create more balanced trees with smaller depths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Which metric is computationally intensive?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split on carbody With Gini Index of 0.214\n",
      "Duration of Gini Index: 0:00:00.017879\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Gini Impurity\n",
    "start_time_gini = datetime.now()\n",
    "def gini_index(dataset, targetcol):\n",
    "    \n",
    "    # store all of our columns and gini scores\n",
    "    gini_scores = []\n",
    "    \n",
    "    # iterate through each column in your dataframe\n",
    "    for col in dataset.columns:\n",
    "        \n",
    "        # skip our target column\n",
    "        # no information gain on target columns!\n",
    "        # we can't split here\n",
    "        if col == targetcol:\n",
    "            continue\n",
    "        \n",
    "        # resets for each column in your dataset\n",
    "        gini = 0\n",
    "        \n",
    "        # get the value counts for that column\n",
    "        unique_values = dataset[col].value_counts()\n",
    "        \n",
    "        # iterate through each unique value for that column\n",
    "        for key, val in unique_values.items():\n",
    "        \n",
    "            # get the target variable seperated, based on\n",
    "            # the independent variable\n",
    "            filteredDf = dataset[targetcol][dataset[col] == key].value_counts()\n",
    "            \n",
    "            # need n for the length\n",
    "            n = len(dataset)\n",
    "            \n",
    "            # sum of the value counts for that column\n",
    "            ValueSum = filteredDf.sum()\n",
    "            \n",
    "            # need the probabilities of each class\n",
    "            p = 0\n",
    "            \n",
    "            # we now have to send it to our gini impurity formula\n",
    "            for i,j in filteredDf.items():\n",
    "                p += (filteredDf[i] / ValueSum) ** 2\n",
    "            \n",
    "            # gini total for column \n",
    "            # is all uniques from each column\n",
    "            gini += (val / n) * (1-p)\n",
    "\n",
    "        \n",
    "        # append our column name and gini score\n",
    "        gini_scores.append((col,gini))\n",
    "    \n",
    "    # sort our gini scores lowest to highest\n",
    "    split_pair = sorted(gini_scores, key=lambda x: -x[1], reverse=True)[0]\n",
    "    \n",
    "    # print out the best score\n",
    "    print(f'''Split on {split_pair[0]} With Gini Index of {round(split_pair[1],3)}''')\n",
    "\n",
    "final = gini_index(df, 'doornumber')\n",
    "end_time_gini = datetime.now()\n",
    "\n",
    "print('Duration of Gini Index: {}'.format(end_time_gini - start_time_gini))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split on fueltype With Information Gain of 0.68\n",
      "Duration of Entropy: 0:00:00.006418\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Entropy\n",
    "start_time_entropy = datetime.now()\n",
    "def entropy(dataset, targetcol):\n",
    "    # store all of our columns and entropy scores\n",
    "    entropy_scores = []\n",
    "    \n",
    "    # iterate through each column in your dataframe\n",
    "    for col in dataset.columns:\n",
    "        \n",
    "        if col == targetcol:\n",
    "            continue\n",
    "        \n",
    "        # get the value_counts normalized, saving us having to iterate through\n",
    "        # each variable\n",
    "        value_counts = dataset[col].value_counts(normalize=True, sort=False)\n",
    "        \n",
    "        # calculate our entropy for the column\n",
    "        entropy = -(value_counts * np.log(value_counts) / np.log(math.e)).sum()\n",
    "        \n",
    "        # append our column name and entropy score\n",
    "        entropy_scores.append((col,entropy))\n",
    "    \n",
    "    # sort our entropy scores lowest to highest\n",
    "    split_pair = sorted(entropy_scores, key=lambda x: -x[1], reverse=True)[0]\n",
    "    \n",
    "    # print out the best score\n",
    "    print(f'''Split on {split_pair[0]} With Information Gain of {round(1-split_pair[1],3)}''')\n",
    "        \n",
    "final = entropy(df, 'carbody')\n",
    "end_time_entropy = datetime.now()\n",
    "\n",
    "print('Duration of Entropy: {}'.format(end_time_entropy - start_time_entropy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The faster method is: Gini Index with time 0:00:00.017879\n"
     ]
    }
   ],
   "source": [
    "gini_index_time = end_time_gini - start_time_gini\n",
    "entropy_time = end_time_entropy - start_time_entropy\n",
    "faster_method = max((gini_index_time, \"Gini Index\"), (entropy_time, \"Entropy\"))\n",
    "\n",
    "print(f'The faster method is: {faster_method[1]} with time {faster_method[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the gini index is computationally less intensive compared to entropy most likely because it does not involve logarithmic functions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "block_b",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
